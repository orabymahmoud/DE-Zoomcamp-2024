{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f75394c-166b-4cdb-8667-f8a5ddf6bcb1",
   "metadata": {},
   "source": [
    "# NY yellow taxi data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "026446ae-5b13-4359-aee0-b1d555ff8366",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting psycopg2\n",
      "  Downloading psycopg2-2.9.9.tar.gz (384 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m384.9/384.9 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: psycopg2\n",
      "  Building wheel for psycopg2 (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for psycopg2: filename=psycopg2-2.9.9-cp310-cp310-linux_x86_64.whl size=584227 sha256=47da6f7a6247b2889a8bc28c8490261c89a7d9cbf9c9229a6aa9d87d26c79d0a\n",
      "  Stored in directory: /home/codespace/.cache/pip/wheels/7d/75/13/da1c6d88687ae81bf5e3cfa07d702981ba137963163472b050\n",
      "Successfully built psycopg2\n",
      "Installing collected packages: psycopg2\n",
      "Successfully installed psycopg2-2.9.9\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install psycopg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "934ea71c-8b89-4c2a-ab2d-f29ca398773a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sqlalchemy\n",
      "  Downloading SQLAlchemy-2.0.25-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.6 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in /home/codespace/.local/lib/python3.10/site-packages (from sqlalchemy) (4.9.0)\n",
      "Collecting greenlet!=0.4.17 (from sqlalchemy)\n",
      "  Downloading greenlet-3.0.3-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (3.8 kB)\n",
      "Downloading SQLAlchemy-2.0.25-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m35.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading greenlet-3.0.3-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (616 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m616.0/616.0 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: greenlet, sqlalchemy\n",
      "Successfully installed greenlet-3.0.3 sqlalchemy-2.0.25\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install sqlalchemy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ffa901f-a081-46eb-aed9-ffd2f1826766",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from time import time\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59b01ad9-4af2-4d10-a543-51db71310f7a",
   "metadata": {},
   "source": [
    "### load csv file to df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "02618627-8453-41dc-ab44-4875e28f2078",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VendorID</th>\n",
       "      <th>lpep_pickup_datetime</th>\n",
       "      <th>lpep_dropoff_datetime</th>\n",
       "      <th>store_and_fwd_flag</th>\n",
       "      <th>RatecodeID</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>extra</th>\n",
       "      <th>mta_tax</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>ehail_fee</th>\n",
       "      <th>improvement_surcharge</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>trip_type</th>\n",
       "      <th>congestion_surcharge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2019-09-01 00:10:53</td>\n",
       "      <td>2019-09-01 00:23:46</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>65</td>\n",
       "      <td>189</td>\n",
       "      <td>5</td>\n",
       "      <td>2.00</td>\n",
       "      <td>10.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.36</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3</td>\n",
       "      <td>14.16</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2019-09-01 00:31:22</td>\n",
       "      <td>2019-09-01 00:44:37</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>97</td>\n",
       "      <td>225</td>\n",
       "      <td>5</td>\n",
       "      <td>3.20</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3</td>\n",
       "      <td>13.30</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2019-09-01 00:50:24</td>\n",
       "      <td>2019-09-01 01:03:20</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>61</td>\n",
       "      <td>5</td>\n",
       "      <td>2.99</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3</td>\n",
       "      <td>13.30</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2019-09-01 00:27:06</td>\n",
       "      <td>2019-09-01 00:33:22</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>145</td>\n",
       "      <td>112</td>\n",
       "      <td>1</td>\n",
       "      <td>1.73</td>\n",
       "      <td>7.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3</td>\n",
       "      <td>10.30</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2019-09-01 00:43:23</td>\n",
       "      <td>2019-09-01 00:59:54</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>112</td>\n",
       "      <td>198</td>\n",
       "      <td>1</td>\n",
       "      <td>3.42</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3</td>\n",
       "      <td>18.36</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   VendorID lpep_pickup_datetime lpep_dropoff_datetime store_and_fwd_flag  \\\n",
       "0         2  2019-09-01 00:10:53   2019-09-01 00:23:46                  N   \n",
       "1         2  2019-09-01 00:31:22   2019-09-01 00:44:37                  N   \n",
       "2         2  2019-09-01 00:50:24   2019-09-01 01:03:20                  N   \n",
       "3         2  2019-09-01 00:27:06   2019-09-01 00:33:22                  N   \n",
       "4         2  2019-09-01 00:43:23   2019-09-01 00:59:54                  N   \n",
       "\n",
       "   RatecodeID  PULocationID  DOLocationID  passenger_count  trip_distance  \\\n",
       "0           1            65           189                5           2.00   \n",
       "1           1            97           225                5           3.20   \n",
       "2           1            37            61                5           2.99   \n",
       "3           1           145           112                1           1.73   \n",
       "4           1           112           198                1           3.42   \n",
       "\n",
       "   fare_amount  extra  mta_tax  tip_amount  tolls_amount  ehail_fee  \\\n",
       "0         10.5    0.5      0.5        2.36           0.0        NaN   \n",
       "1         12.0    0.5      0.5        0.00           0.0        NaN   \n",
       "2         12.0    0.5      0.5        0.00           0.0        NaN   \n",
       "3          7.5    0.5      0.5        1.50           0.0        NaN   \n",
       "4         14.0    0.5      0.5        3.06           0.0        NaN   \n",
       "\n",
       "   improvement_surcharge  total_amount  payment_type  trip_type  \\\n",
       "0                    0.3         14.16             1          1   \n",
       "1                    0.3         13.30             2          1   \n",
       "2                    0.3         13.30             2          1   \n",
       "3                    0.3         10.30             1          1   \n",
       "4                    0.3         18.36             1          1   \n",
       "\n",
       "   congestion_surcharge  \n",
       "0                   0.0  \n",
       "1                   0.0  \n",
       "2                   0.0  \n",
       "3                   0.0  \n",
       "4                   0.0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('/workspaces/DE-Zoomcamp-2024/data/green_tripdata_2019-09.csv', nrows=100)\n",
    "df.head(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd928c69-7ab3-46b7-a989-ee6b631d88e4",
   "metadata": {},
   "source": [
    "### Edit datatime format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "acbdf23f-e435-4a37-90da-d6812abf2ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['lpep_pickup_datetime'] = pd.to_datetime(df['lpep_pickup_datetime'], format='%Y-%m-%d %H:%M:%S')\n",
    "df['lpep_dropoff_datetime'] = pd.to_datetime(df['lpep_dropoff_datetime'], format='%Y-%m-%d %H:%M:%S')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5e9fcf6-2960-4aa7-881b-9575981ede4a",
   "metadata": {},
   "source": [
    "### Create db engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b78a620b-0d6d-49ef-8816-3118ceeaf8f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine('postgresql://root:root@localhost:5432/ny_taxi')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b11561a-1b3d-4fc1-939c-128620c7b80c",
   "metadata": {},
   "source": [
    "### Get  DDL from the dataframe to create the table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3247759e-24d4-4e4e-a2cd-2026167e77d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CREATE TABLE ny_yellow_taxi_data (\n",
      "\t\"VendorID\" BIGINT, \n",
      "\tlpep_pickup_datetime TIMESTAMP WITHOUT TIME ZONE, \n",
      "\tlpep_dropoff_datetime TIMESTAMP WITHOUT TIME ZONE, \n",
      "\tstore_and_fwd_flag TEXT, \n",
      "\t\"RatecodeID\" BIGINT, \n",
      "\t\"PULocationID\" BIGINT, \n",
      "\t\"DOLocationID\" BIGINT, \n",
      "\tpassenger_count BIGINT, \n",
      "\ttrip_distance FLOAT(53), \n",
      "\tfare_amount FLOAT(53), \n",
      "\textra FLOAT(53), \n",
      "\tmta_tax FLOAT(53), \n",
      "\ttip_amount FLOAT(53), \n",
      "\ttolls_amount FLOAT(53), \n",
      "\tehail_fee FLOAT(53), \n",
      "\timprovement_surcharge FLOAT(53), \n",
      "\ttotal_amount FLOAT(53), \n",
      "\tpayment_type BIGINT, \n",
      "\ttrip_type BIGINT, \n",
      "\tcongestion_surcharge FLOAT(53)\n",
      ")\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(pd.io.sql.get_schema(df , 'ny_yellow_taxi_data' ,con = engine))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfaac382-4d0b-480b-980b-9fcb5d4aa1c8",
   "metadata": {},
   "source": [
    "### Split the data into chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4153fd6e-87ac-4e43-87c0-f811f1a194d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_iter = pd.read_csv('/workspaces/DE-Zoomcamp-2024/data/green_tripdata_2019-09.csv' , iterator = True , chunksize = 100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ac93c737-7ad1-47a7-b7d6-2887bbca7505",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = next(df_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8264a66-587c-4edd-ac54-9ba47a505624",
   "metadata": {},
   "source": [
    "### Create the table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b5a5ee61-caaf-46d6-93e3-8179e6e01aba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(0).to_sql('ny_yellow_taxi', engine, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9c26ebd-f9ae-4afb-8928-2fbe1b603003",
   "metadata": {},
   "source": [
    "### Iterate over chunks and load into PostgreSQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "411a62c7-ddfd-44be-bebf-1e3f05a69877",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1 loaded into PostgreSQL. Elapsed Time: 9.85 seconds\n",
      "Chunk 2 loaded into PostgreSQL. Elapsed Time: 10.10 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_12664/765277001.py:1: DtypeWarning: Columns (3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for i, chunk in enumerate(df_iter):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 3 loaded into PostgreSQL. Elapsed Time: 10.03 seconds\n",
      "Chunk 4 loaded into PostgreSQL. Elapsed Time: 4.05 seconds\n",
      "Data loading complete.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i, chunk in enumerate(df_iter):\n",
    "    start_time = time()\n",
    "    chunk['lpep_pickup_datetime'] = pd.to_datetime(chunk['lpep_pickup_datetime'], format='%Y-%m-%d %H:%M:%S')\n",
    "    chunk['lpep_dropoff_datetime'] = pd.to_datetime(chunk['lpep_dropoff_datetime'], format='%Y-%m-%d %H:%M:%S')\n",
    "    chunk.to_sql('ny_yellow_taxi', engine, if_exists='append', index=False)\n",
    "    \n",
    "    end_time = time()\n",
    "    elapsed_time = end_time - start_time\n",
    "\n",
    "    print(f'Chunk {i + 1} loaded into PostgreSQL. Elapsed Time: {elapsed_time:.2f} seconds')\n",
    "\n",
    "print('Data loading complete.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb713947-d1c2-4993-af1a-53df242a58a8",
   "metadata": {},
   "source": [
    "### load_csv_to_postgres function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19546ae7-02bc-4237-b9a0-00b6306ab91a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, inspect\n",
    "import time\n",
    "\n",
    "def load_csv_to_postgres(engine, table_name, file_path, chunk_size=100000):\n",
    "    # Check if table exists\n",
    "    inspector = inspect(engine)\n",
    "    if not inspector.has_table(table_name):\n",
    "        print(f'Table {table_name} does not exist. Creating...')\n",
    "        # Assume the first chunk has the column names\n",
    "        first_chunk = pd.read_csv(file_path, nrows=1)\n",
    "        first_chunk.to_sql(table_name, engine, index=False)\n",
    "\n",
    "    # Read CSV in chunks\n",
    "    df_iter = pd.read_csv(file_path, iterator=True, chunksize=chunk_size)\n",
    "\n",
    "    # Iterate over chunks and load into PostgreSQL\n",
    "    for i, chunk in enumerate(df_iter):\n",
    "        start_time = time.time()\n",
    "\n",
    "        # Modify chunk processing as needed\n",
    "        chunk.to_sql(table_name, engine, if_exists='append', index=False)\n",
    "\n",
    "        end_time = time.time()\n",
    "        elapsed_time = end_time - start_time\n",
    "        print(f'Chunk {i + 1} loaded into PostgreSQL. Elapsed Time: {elapsed_time:.2f} seconds')\n",
    "\n",
    "    print('Data loading complete.')\n",
    "\n",
    "# Example usage:\n",
    "# Replace 'your_postgres_url' and 'your_table_name' with actual values\n",
    "db_url = 'postgresql://root:root@localhost:5432/ny_taxi'\n",
    "table_name = 'zones'\n",
    "file_path = '/workspaces/DE-Zoomcamp-2024/data/zone_lookup.csv'\n",
    "engine = create_engine(db_url)\n",
    "\n",
    "# Call the function\n",
    "load_csv_to_postgres(engine, table_name, file_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
